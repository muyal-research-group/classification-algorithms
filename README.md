# Axo - Classification Algorithms

This repository provides a collection of **classification algorithms** implemented in Python with a unified structure.  
All algorithms are integrated with [Axo](https://github.com/muyal-research-group/axo/tree/dev) to provide **standardized training, prediction, metrics, and visualization**.  

The project is designed to:  
- Ensure **consistent method names** across all  decorated algorithms (`train`, `predict`).  
- Use **typing** (`npt.NDArray`, `Dict`, `Any`, etc.) everywhere possible.  
- Be fully testable using **pytest**.  

## ğŸ“¦ Installation

### Option 1: Using [Poetry](https://python-poetry.org/)
```bash
poetry install

To install from the prebuilt package:
```bash
poetry add axo==0.0.1a12 
```

âš ï¸ please use the newest version of Axo you can check it  https://github.com/muyal-research-group/axo


---

## ğŸ“‚ Project Structure  
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ classification_algorithms
â”‚ â”œâ”€â”€ decission_tree.py
â”‚ â”œâ”€â”€ linear_regression.py
â”‚ â”œâ”€â”€ logistic_regression.py
â”‚ â”œâ”€â”€ naive_bayes.py
â”‚ â”œâ”€â”€ perceptron
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â”œâ”€â”€ multicapa.py
â”‚ â”‚ â””â”€â”€ perceptron.py
â”‚ â””â”€â”€ svm.py
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â””â”€â”€ tests
â”œâ”€â”€ init.py
â””â”€â”€ test_perceptron.py
```

## âš¡ Example Usage  

The `Perceptron` implementation serves as the **reference example**.  
All other algorithms (`DecisionTree`, `LogisticRegression`, `NaiveBayes`, `SVM`, etc.) will follow the same pattern.  

```python
from classification_algorithms.perceptron.perceptron import Perceptron
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from axo.contextmanager import AxoContextManager

# Generate dataset
X, y = make_classification(n_samples=200, n_features=8, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

with AxoContextManager.local() as lr:
    # Initialize model 
    p = Perceptron(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)

    # Train
    params = p.train()
    print("Model parameters:", params)

    # Predict
    y_pred = p.predict()
    print("Predictions:", y_pred)
```

## ğŸ§ª Testing

We use pytest for testing all classification algorithms.

Run the tests with:
```bash 
pytest ./tests -s -vv
```

### ğŸ“ Code Coverage
To evaluate how much of the codebase is exercised by the test suite, we use ```coverage```

```sh
coverage run -m pytest tests/
coverage report -m
```

- ```coverage run``` wraps the pytest invocation to trace executed statements.

- ```coverage report -m``` generates a summary including missing lines and module

This allows us to:

- Identify untested logic or edge cases.

- Focus testing efforts on high-risk areas.

- Prevent regressions by maintaining coverage thresholds over time.

You can also generate an HTML report for visual inspection:

```sh
coverage html
```
Then open ```htmlcov/index.html``` in your browser to explore annotated source files with coverage information.

## License

This project is licensed under the MIT License.
